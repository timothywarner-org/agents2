# ============================================================================
# O'Reilly AI Agents MVP - Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your values.
# NEVER commit .env to version control!
# ============================================================================

# ----------------------------------------------------------------------------
# LLM Provider Configuration
# Choose ONE provider: azure | openai | anthropic
# ----------------------------------------------------------------------------

# OPTION 1: Azure OpenAI (Recommended for enterprise)
# Uncomment and fill in your Azure details
LLM_PROVIDER=azure
AZURE_OPENAI_ENDPOINT=https://YOUR-RESOURCE.openai.azure.com/
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# OPTION 2: DeepSeek (OpenAI-compatible API)
# Uncomment these and comment out Azure settings above
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your-deepseek-api-key
# OPENAI_BASE_URL=https://api.deepseek.com
# LLM_MODEL=deepseek-chat

# OPTION 3: Anthropic Claude
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=your-anthropic-api-key
# LLM_MODEL=claude-sonnet-4-20250514

# OPTION 4: OpenAI Direct
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your-openai-api-key
# LLM_MODEL=gpt-4o

# ----------------------------------------------------------------------------
# Model Configuration
# ----------------------------------------------------------------------------

# Temperature for LLM responses (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.2

# ----------------------------------------------------------------------------
# Runtime Configuration
# ----------------------------------------------------------------------------

# Folder watcher poll interval in seconds
WATCH_POLL_SECONDS=3

# LangGraph checkpoint storage (optional - leave empty for in-memory)
LANGGRAPH_CHECKPOINT_PATH=

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# GitHub MCP Configuration
# Used by VS Code MCP / Claude Code for GitHub integration
# NOT used by Python runtime directly
# ----------------------------------------------------------------------------

# Get a Personal Access Token at: https://github.com/settings/tokens
# Required scopes: repo, read:org (for private repos)
GITHUB_TOKEN=your-github-personal-access-token
