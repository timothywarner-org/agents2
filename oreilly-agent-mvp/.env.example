# ============================================================================
# O'Reilly AI Agents MVP - Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your values.
# NEVER commit .env to version control!
# ============================================================================

# ----------------------------------------------------------------------------
# LLM Provider Configuration
# Choose ONE provider and fill in its credentials.
# Set LLM_PROVIDER to: anthropic | openai | azure
# ----------------------------------------------------------------------------

LLM_PROVIDER=anthropic

# --- Anthropic (Claude) ---
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# --- OpenAI ---
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# --- Azure OpenAI ---
# Get credentials from your Azure Portal > Azure OpenAI resource
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_DEPLOYMENT=
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# ----------------------------------------------------------------------------
# Model Configuration
# ----------------------------------------------------------------------------

# Model name to use (provider-specific)
# Anthropic: claude-sonnet-4-20250514, claude-3-5-haiku-20241022
# OpenAI: gpt-4o, gpt-4o-mini
# Azure: Your deployment name (same as AZURE_OPENAI_DEPLOYMENT)
LLM_MODEL=claude-sonnet-4-20250514

# Temperature for LLM responses (0.0 = deterministic, 1.0 = creative)
# Keep low for reproducible outputs in demos
LLM_TEMPERATURE=0.2

# ----------------------------------------------------------------------------
# Runtime Configuration
# ----------------------------------------------------------------------------

# Folder watcher poll interval in seconds
WATCH_POLL_SECONDS=3

# LangGraph checkpoint storage (optional - for state persistence)
# Leave empty for in-memory only (simpler for demos)
LANGGRAPH_CHECKPOINT_PATH=

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# GitHub MCP Configuration (for VS Code / Claude Code integration)
# These are NOT used by the Python runtime directly.
# See .vscode/mcp.json and .mcp.json for MCP tool configuration.
# ----------------------------------------------------------------------------

# GITHUB_TOKEN is used by GitHub MCP server for authentication
# Get a Personal Access Token at: https://github.com/settings/tokens
# Required scopes: repo, read:org (for private repos)
GITHUB_TOKEN=
